{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=\"/home/aluno/4522/reviews_data.txt.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "with gzip.open ('/home/aluno/4522/reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(input_file):  \n",
    "    logging.info(\"lendo o arquivo {0}...isto pode demorar um pouco\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            yield gensim.utils.simple_preprocess (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-08 12:34:17,333 : INFO : lendo o arquivo /home/aluno/4522/reviews_data.txt.gz...isto pode demorar um pouco\n",
      "2019-11-08 12:34:17,340 : INFO : read 0 reviews\n",
      "2019-11-08 12:34:19,748 : INFO : read 10000 reviews\n",
      "2019-11-08 12:34:21,466 : INFO : read 20000 reviews\n",
      "2019-11-08 12:34:24,535 : INFO : read 30000 reviews\n",
      "2019-11-08 12:34:26,353 : INFO : read 40000 reviews\n",
      "2019-11-08 12:34:29,068 : INFO : read 50000 reviews\n",
      "2019-11-08 12:34:31,139 : INFO : read 60000 reviews\n",
      "2019-11-08 12:34:32,925 : INFO : read 70000 reviews\n",
      "2019-11-08 12:34:34,429 : INFO : read 80000 reviews\n",
      "2019-11-08 12:34:36,024 : INFO : read 90000 reviews\n",
      "2019-11-08 12:34:37,582 : INFO : read 100000 reviews\n",
      "2019-11-08 12:34:39,128 : INFO : read 110000 reviews\n",
      "2019-11-08 12:34:40,674 : INFO : read 120000 reviews\n",
      "2019-11-08 12:34:42,280 : INFO : read 130000 reviews\n",
      "2019-11-08 12:34:43,978 : INFO : read 140000 reviews\n",
      "2019-11-08 12:34:45,534 : INFO : read 150000 reviews\n",
      "2019-11-08 12:34:47,458 : INFO : read 160000 reviews\n",
      "2019-11-08 12:34:49,024 : INFO : read 170000 reviews\n",
      "2019-11-08 12:34:50,815 : INFO : read 180000 reviews\n",
      "2019-11-08 12:34:52,482 : INFO : read 190000 reviews\n",
      "2019-11-08 12:34:54,239 : INFO : read 200000 reviews\n",
      "2019-11-08 12:34:55,906 : INFO : read 210000 reviews\n",
      "2019-11-08 12:34:57,592 : INFO : read 220000 reviews\n",
      "2019-11-08 12:34:59,142 : INFO : read 230000 reviews\n",
      "2019-11-08 12:35:00,775 : INFO : read 240000 reviews\n",
      "2019-11-08 12:35:02,871 : INFO : read 250000 reviews\n",
      "2019-11-08 12:35:03,727 : INFO : Leitura do arquivo finalizada!\n"
     ]
    }
   ],
   "source": [
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Leitura do arquivo finalizada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-08 15:20:09,415 : INFO : collecting all words and their counts\n",
      "2019-11-08 15:20:09,423 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-08 15:20:09,675 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2019-11-08 15:20:09,860 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2019-11-08 15:20:10,079 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2019-11-08 15:20:10,290 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2019-11-08 15:20:10,545 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2019-11-08 15:20:10,791 : INFO : PROGRESS: at sentence #60000, processed 11013723 words, keeping 76781 word types\n",
      "2019-11-08 15:20:10,982 : INFO : PROGRESS: at sentence #70000, processed 12637525 words, keeping 83194 word types\n",
      "2019-11-08 15:20:11,158 : INFO : PROGRESS: at sentence #80000, processed 14099751 words, keeping 88454 word types\n",
      "2019-11-08 15:20:11,346 : INFO : PROGRESS: at sentence #90000, processed 15662149 words, keeping 93352 word types\n",
      "2019-11-08 15:20:11,528 : INFO : PROGRESS: at sentence #100000, processed 17164487 words, keeping 97881 word types\n",
      "2019-11-08 15:20:11,707 : INFO : PROGRESS: at sentence #110000, processed 18652292 words, keeping 102127 word types\n",
      "2019-11-08 15:20:11,885 : INFO : PROGRESS: at sentence #120000, processed 20152529 words, keeping 105918 word types\n",
      "2019-11-08 15:20:12,069 : INFO : PROGRESS: at sentence #130000, processed 21684330 words, keeping 110099 word types\n",
      "2019-11-08 15:20:12,261 : INFO : PROGRESS: at sentence #140000, processed 23330206 words, keeping 114103 word types\n",
      "2019-11-08 15:20:12,445 : INFO : PROGRESS: at sentence #150000, processed 24838754 words, keeping 118169 word types\n",
      "2019-11-08 15:20:12,630 : INFO : PROGRESS: at sentence #160000, processed 26390910 words, keeping 118665 word types\n",
      "2019-11-08 15:20:12,812 : INFO : PROGRESS: at sentence #170000, processed 27913916 words, keeping 123350 word types\n",
      "2019-11-08 15:20:13,001 : INFO : PROGRESS: at sentence #180000, processed 29535612 words, keeping 126742 word types\n",
      "2019-11-08 15:20:13,184 : INFO : PROGRESS: at sentence #190000, processed 31096459 words, keeping 129841 word types\n",
      "2019-11-08 15:20:13,394 : INFO : PROGRESS: at sentence #200000, processed 32805271 words, keeping 133249 word types\n",
      "2019-11-08 15:20:13,594 : INFO : PROGRESS: at sentence #210000, processed 34434198 words, keeping 136358 word types\n",
      "2019-11-08 15:20:13,792 : INFO : PROGRESS: at sentence #220000, processed 36083482 words, keeping 139412 word types\n",
      "2019-11-08 15:20:14,006 : INFO : PROGRESS: at sentence #230000, processed 37571762 words, keeping 142393 word types\n",
      "2019-11-08 15:20:14,214 : INFO : PROGRESS: at sentence #240000, processed 39138190 words, keeping 145226 word types\n",
      "2019-11-08 15:20:14,432 : INFO : PROGRESS: at sentence #250000, processed 40695049 words, keeping 147960 word types\n",
      "2019-11-08 15:20:14,547 : INFO : collected 150053 word types from a corpus of 41519355 raw words and 255404 sentences\n",
      "2019-11-08 15:20:14,552 : INFO : Loading a fresh vocabulary\n",
      "2019-11-08 15:20:15,484 : INFO : effective_min_count=2 retains 70538 unique words (47% of original 150053, drops 79515)\n",
      "2019-11-08 15:20:15,490 : INFO : effective_min_count=2 leaves 41439840 word corpus (99% of original 41519355, drops 79515)\n",
      "2019-11-08 15:20:15,713 : INFO : deleting the raw counts dictionary of 150053 items\n",
      "2019-11-08 15:20:15,723 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2019-11-08 15:20:15,729 : INFO : downsampling leaves estimated 30349255 word corpus (73.2% of prior 41439840)\n",
      "2019-11-08 15:20:16,022 : INFO : estimated required memory for 70538 words and 200 dimensions: 148129800 bytes\n",
      "2019-11-08 15:20:16,027 : INFO : resetting layer weights\n",
      "2019-11-08 15:20:17,243 : INFO : training model with 10 workers on 70538 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=3\n",
      "2019-11-08 15:20:18,260 : INFO : EPOCH 1 - PROGRESS: at 0.90% examples, 294575 words/s, in_qsize 17, out_qsize 5\n",
      "2019-11-08 15:20:19,339 : INFO : EPOCH 1 - PROGRESS: at 2.52% examples, 380822 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:20,395 : INFO : EPOCH 1 - PROGRESS: at 3.96% examples, 390547 words/s, in_qsize 16, out_qsize 3\n",
      "2019-11-08 15:20:21,399 : INFO : EPOCH 1 - PROGRESS: at 5.39% examples, 400306 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:20:22,419 : INFO : EPOCH 1 - PROGRESS: at 7.01% examples, 417467 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:23,501 : INFO : EPOCH 1 - PROGRESS: at 8.63% examples, 426853 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:20:24,579 : INFO : EPOCH 1 - PROGRESS: at 9.94% examples, 432554 words/s, in_qsize 19, out_qsize 4\n",
      "2019-11-08 15:20:25,639 : INFO : EPOCH 1 - PROGRESS: at 11.35% examples, 437103 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:26,659 : INFO : EPOCH 1 - PROGRESS: at 12.61% examples, 443185 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:27,771 : INFO : EPOCH 1 - PROGRESS: at 13.56% examples, 424378 words/s, in_qsize 20, out_qsize 2\n",
      "2019-11-08 15:20:28,781 : INFO : EPOCH 1 - PROGRESS: at 14.87% examples, 427781 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:29,838 : INFO : EPOCH 1 - PROGRESS: at 16.20% examples, 427486 words/s, in_qsize 19, out_qsize 4\n",
      "2019-11-08 15:20:30,839 : INFO : EPOCH 1 - PROGRESS: at 17.54% examples, 432648 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:31,849 : INFO : EPOCH 1 - PROGRESS: at 18.75% examples, 432695 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:20:32,899 : INFO : EPOCH 1 - PROGRESS: at 20.01% examples, 435615 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:33,931 : INFO : EPOCH 1 - PROGRESS: at 21.57% examples, 438267 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:34,981 : INFO : EPOCH 1 - PROGRESS: at 22.72% examples, 436691 words/s, in_qsize 20, out_qsize 6\n",
      "2019-11-08 15:20:35,981 : INFO : EPOCH 1 - PROGRESS: at 23.98% examples, 440649 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:20:37,012 : INFO : EPOCH 1 - PROGRESS: at 25.33% examples, 439127 words/s, in_qsize 18, out_qsize 1\n",
      "2019-11-08 15:20:38,052 : INFO : EPOCH 1 - PROGRESS: at 27.19% examples, 441133 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:39,121 : INFO : EPOCH 1 - PROGRESS: at 28.74% examples, 439058 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:20:40,239 : INFO : EPOCH 1 - PROGRESS: at 30.52% examples, 439961 words/s, in_qsize 18, out_qsize 2\n",
      "2019-11-08 15:20:41,241 : INFO : EPOCH 1 - PROGRESS: at 32.40% examples, 442309 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:42,382 : INFO : EPOCH 1 - PROGRESS: at 33.84% examples, 439727 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:43,441 : INFO : EPOCH 1 - PROGRESS: at 35.61% examples, 441309 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:20:44,609 : INFO : EPOCH 1 - PROGRESS: at 37.38% examples, 440903 words/s, in_qsize 19, out_qsize 3\n",
      "2019-11-08 15:20:45,669 : INFO : EPOCH 1 - PROGRESS: at 39.40% examples, 443948 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:20:46,699 : INFO : EPOCH 1 - PROGRESS: at 40.99% examples, 443835 words/s, in_qsize 19, out_qsize 5\n",
      "2019-11-08 15:20:47,801 : INFO : EPOCH 1 - PROGRESS: at 43.07% examples, 446429 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:48,863 : INFO : EPOCH 1 - PROGRESS: at 44.99% examples, 447637 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:20:49,876 : INFO : EPOCH 1 - PROGRESS: at 46.73% examples, 449192 words/s, in_qsize 18, out_qsize 1\n",
      "2019-11-08 15:20:51,080 : INFO : EPOCH 1 - PROGRESS: at 48.17% examples, 445790 words/s, in_qsize 19, out_qsize 6\n",
      "2019-11-08 15:20:52,101 : INFO : EPOCH 1 - PROGRESS: at 49.94% examples, 446970 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:53,129 : INFO : EPOCH 1 - PROGRESS: at 51.16% examples, 444201 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:54,224 : INFO : EPOCH 1 - PROGRESS: at 52.17% examples, 439190 words/s, in_qsize 20, out_qsize 8\n",
      "2019-11-08 15:20:55,289 : INFO : EPOCH 1 - PROGRESS: at 53.52% examples, 438058 words/s, in_qsize 19, out_qsize 3\n",
      "2019-11-08 15:20:56,291 : INFO : EPOCH 1 - PROGRESS: at 55.26% examples, 439413 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-08 15:20:57,339 : INFO : EPOCH 1 - PROGRESS: at 56.54% examples, 437132 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:20:58,374 : INFO : EPOCH 1 - PROGRESS: at 58.05% examples, 436835 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:20:59,378 : INFO : EPOCH 1 - PROGRESS: at 59.65% examples, 437237 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:00,448 : INFO : EPOCH 1 - PROGRESS: at 61.27% examples, 437332 words/s, in_qsize 19, out_qsize 3\n",
      "2019-11-08 15:21:01,481 : INFO : EPOCH 1 - PROGRESS: at 62.99% examples, 438563 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:21:02,519 : INFO : EPOCH 1 - PROGRESS: at 64.94% examples, 439478 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:21:03,524 : INFO : EPOCH 1 - PROGRESS: at 66.53% examples, 440801 words/s, in_qsize 17, out_qsize 3\n",
      "2019-11-08 15:21:04,583 : INFO : EPOCH 1 - PROGRESS: at 68.24% examples, 441565 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:21:05,652 : INFO : EPOCH 1 - PROGRESS: at 69.87% examples, 442059 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:06,711 : INFO : EPOCH 1 - PROGRESS: at 71.50% examples, 442813 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:07,741 : INFO : EPOCH 1 - PROGRESS: at 73.22% examples, 443621 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:08,801 : INFO : EPOCH 1 - PROGRESS: at 74.90% examples, 444000 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:09,848 : INFO : EPOCH 1 - PROGRESS: at 76.05% examples, 442290 words/s, in_qsize 19, out_qsize 4\n",
      "2019-11-08 15:21:10,898 : INFO : EPOCH 1 - PROGRESS: at 77.59% examples, 442871 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:12,008 : INFO : EPOCH 1 - PROGRESS: at 79.27% examples, 443236 words/s, in_qsize 18, out_qsize 1\n",
      "2019-11-08 15:21:13,029 : INFO : EPOCH 1 - PROGRESS: at 80.85% examples, 444033 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:14,071 : INFO : EPOCH 1 - PROGRESS: at 82.33% examples, 443612 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:15,081 : INFO : EPOCH 1 - PROGRESS: at 83.98% examples, 444469 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:16,099 : INFO : EPOCH 1 - PROGRESS: at 85.31% examples, 444090 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:17,150 : INFO : EPOCH 1 - PROGRESS: at 86.86% examples, 443634 words/s, in_qsize 17, out_qsize 2\n",
      "2019-11-08 15:21:18,215 : INFO : EPOCH 1 - PROGRESS: at 88.72% examples, 444189 words/s, in_qsize 19, out_qsize 5\n",
      "2019-11-08 15:21:19,229 : INFO : EPOCH 1 - PROGRESS: at 90.49% examples, 445094 words/s, in_qsize 19, out_qsize 4\n",
      "2019-11-08 15:21:20,234 : INFO : EPOCH 1 - PROGRESS: at 92.23% examples, 445906 words/s, in_qsize 19, out_qsize 5\n",
      "2019-11-08 15:21:21,258 : INFO : EPOCH 1 - PROGRESS: at 93.90% examples, 446636 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:21:22,391 : INFO : EPOCH 1 - PROGRESS: at 95.65% examples, 446645 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:21:23,399 : INFO : EPOCH 1 - PROGRESS: at 97.18% examples, 446578 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:24,433 : INFO : EPOCH 1 - PROGRESS: at 98.59% examples, 445815 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:25,715 : INFO : EPOCH 1 - PROGRESS: at 99.59% examples, 441684 words/s, in_qsize 14, out_qsize 2\n",
      "2019-11-08 15:21:25,717 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-11-08 15:21:25,719 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-11-08 15:21:25,720 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-08 15:21:25,809 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-08 15:21:25,870 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-08 15:21:25,872 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-08 15:21:25,876 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-08 15:21:25,878 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-08 15:21:25,889 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-08 15:21:25,891 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-08 15:21:25,897 : INFO : EPOCH - 1 : training on 41519355 raw words (30350586 effective words) took 68.6s, 442144 effective words/s\n",
      "2019-11-08 15:21:26,908 : INFO : EPOCH 2 - PROGRESS: at 0.70% examples, 222832 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:28,059 : INFO : EPOCH 2 - PROGRESS: at 1.61% examples, 234890 words/s, in_qsize 20, out_qsize 2\n",
      "2019-11-08 15:21:29,188 : INFO : EPOCH 2 - PROGRESS: at 2.98% examples, 281034 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:30,248 : INFO : EPOCH 2 - PROGRESS: at 4.38% examples, 310481 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:21:31,429 : INFO : EPOCH 2 - PROGRESS: at 5.53% examples, 309341 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:32,547 : INFO : EPOCH 2 - PROGRESS: at 6.96% examples, 322219 words/s, in_qsize 19, out_qsize 4\n",
      "2019-11-08 15:21:33,583 : INFO : EPOCH 2 - PROGRESS: at 7.84% examples, 316217 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:21:34,619 : INFO : EPOCH 2 - PROGRESS: at 8.95% examples, 319867 words/s, in_qsize 19, out_qsize 4\n",
      "2019-11-08 15:21:35,669 : INFO : EPOCH 2 - PROGRESS: at 10.10% examples, 329592 words/s, in_qsize 19, out_qsize 3\n",
      "2019-11-08 15:21:36,687 : INFO : EPOCH 2 - PROGRESS: at 11.47% examples, 345211 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:21:37,708 : INFO : EPOCH 2 - PROGRESS: at 12.79% examples, 357977 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:21:38,729 : INFO : EPOCH 2 - PROGRESS: at 14.30% examples, 368219 words/s, in_qsize 19, out_qsize 3\n",
      "2019-11-08 15:21:39,769 : INFO : EPOCH 2 - PROGRESS: at 15.78% examples, 376555 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:40,791 : INFO : EPOCH 2 - PROGRESS: at 16.96% examples, 379716 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:41,843 : INFO : EPOCH 2 - PROGRESS: at 18.31% examples, 386284 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:21:42,893 : INFO : EPOCH 2 - PROGRESS: at 19.61% examples, 391924 words/s, in_qsize 18, out_qsize 1\n",
      "2019-11-08 15:21:44,007 : INFO : EPOCH 2 - PROGRESS: at 20.87% examples, 395561 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:21:45,051 : INFO : EPOCH 2 - PROGRESS: at 22.49% examples, 399764 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:46,187 : INFO : EPOCH 2 - PROGRESS: at 23.76% examples, 402196 words/s, in_qsize 19, out_qsize 3\n",
      "2019-11-08 15:21:47,237 : INFO : EPOCH 2 - PROGRESS: at 25.03% examples, 402621 words/s, in_qsize 17, out_qsize 2\n",
      "2019-11-08 15:21:48,239 : INFO : EPOCH 2 - PROGRESS: at 26.64% examples, 403964 words/s, in_qsize 17, out_qsize 3\n",
      "2019-11-08 15:21:49,281 : INFO : EPOCH 2 - PROGRESS: at 28.46% examples, 407285 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:50,341 : INFO : EPOCH 2 - PROGRESS: at 30.21% examples, 410230 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:51,348 : INFO : EPOCH 2 - PROGRESS: at 31.93% examples, 411330 words/s, in_qsize 19, out_qsize 4\n",
      "2019-11-08 15:21:52,361 : INFO : EPOCH 2 - PROGRESS: at 33.40% examples, 411896 words/s, in_qsize 19, out_qsize 5\n",
      "2019-11-08 15:21:53,421 : INFO : EPOCH 2 - PROGRESS: at 35.06% examples, 414446 words/s, in_qsize 20, out_qsize 2\n",
      "2019-11-08 15:21:54,496 : INFO : EPOCH 2 - PROGRESS: at 36.88% examples, 416540 words/s, in_qsize 19, out_qsize 5\n",
      "2019-11-08 15:21:55,589 : INFO : EPOCH 2 - PROGRESS: at 38.65% examples, 417918 words/s, in_qsize 18, out_qsize 2\n",
      "2019-11-08 15:21:56,590 : INFO : EPOCH 2 - PROGRESS: at 40.41% examples, 420737 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:21:57,611 : INFO : EPOCH 2 - PROGRESS: at 42.05% examples, 420617 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:21:58,709 : INFO : EPOCH 2 - PROGRESS: at 43.57% examples, 419941 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:21:59,946 : INFO : EPOCH 2 - PROGRESS: at 44.91% examples, 415041 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:22:00,959 : INFO : EPOCH 2 - PROGRESS: at 46.64% examples, 417240 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:02,034 : INFO : EPOCH 2 - PROGRESS: at 47.90% examples, 415009 words/s, in_qsize 19, out_qsize 3\n",
      "2019-11-08 15:22:03,089 : INFO : EPOCH 2 - PROGRESS: at 49.66% examples, 416792 words/s, in_qsize 19, out_qsize 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-08 15:22:04,119 : INFO : EPOCH 2 - PROGRESS: at 51.38% examples, 418716 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:22:05,125 : INFO : EPOCH 2 - PROGRESS: at 52.98% examples, 420790 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:22:06,149 : INFO : EPOCH 2 - PROGRESS: at 54.20% examples, 419046 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:22:07,161 : INFO : EPOCH 2 - PROGRESS: at 56.04% examples, 421061 words/s, in_qsize 16, out_qsize 4\n",
      "2019-11-08 15:22:08,280 : INFO : EPOCH 2 - PROGRESS: at 57.76% examples, 421868 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:22:09,331 : INFO : EPOCH 2 - PROGRESS: at 59.52% examples, 423302 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:22:10,375 : INFO : EPOCH 2 - PROGRESS: at 61.27% examples, 424786 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:22:11,428 : INFO : EPOCH 2 - PROGRESS: at 63.00% examples, 426081 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:22:12,469 : INFO : EPOCH 2 - PROGRESS: at 64.96% examples, 427389 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:13,471 : INFO : EPOCH 2 - PROGRESS: at 66.28% examples, 427434 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:22:14,479 : INFO : EPOCH 2 - PROGRESS: at 67.96% examples, 428472 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:15,499 : INFO : EPOCH 2 - PROGRESS: at 69.61% examples, 429959 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:16,528 : INFO : EPOCH 2 - PROGRESS: at 71.22% examples, 431204 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:17,530 : INFO : EPOCH 2 - PROGRESS: at 72.78% examples, 431487 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:22:18,594 : INFO : EPOCH 2 - PROGRESS: at 74.51% examples, 432199 words/s, in_qsize 17, out_qsize 5\n",
      "2019-11-08 15:22:19,649 : INFO : EPOCH 2 - PROGRESS: at 76.10% examples, 433105 words/s, in_qsize 20, out_qsize 3\n",
      "2019-11-08 15:22:20,679 : INFO : EPOCH 2 - PROGRESS: at 77.65% examples, 434153 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:21,679 : INFO : EPOCH 2 - PROGRESS: at 79.17% examples, 434752 words/s, in_qsize 18, out_qsize 0\n",
      "2019-11-08 15:22:22,709 : INFO : EPOCH 2 - PROGRESS: at 79.97% examples, 431181 words/s, in_qsize 15, out_qsize 5\n",
      "2019-11-08 15:22:23,721 : INFO : EPOCH 2 - PROGRESS: at 81.82% examples, 433342 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:24,758 : INFO : EPOCH 2 - PROGRESS: at 83.52% examples, 434260 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:25,958 : INFO : EPOCH 2 - PROGRESS: at 84.43% examples, 430496 words/s, in_qsize 20, out_qsize 2\n",
      "2019-11-08 15:22:27,146 : INFO : EPOCH 2 - PROGRESS: at 86.31% examples, 431400 words/s, in_qsize 18, out_qsize 1\n",
      "2019-11-08 15:22:28,155 : INFO : EPOCH 2 - PROGRESS: at 88.13% examples, 432529 words/s, in_qsize 18, out_qsize 2\n",
      "2019-11-08 15:22:29,169 : INFO : EPOCH 2 - PROGRESS: at 89.94% examples, 433599 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:22:30,195 : INFO : EPOCH 2 - PROGRESS: at 91.71% examples, 434553 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:31,214 : INFO : EPOCH 2 - PROGRESS: at 93.39% examples, 435499 words/s, in_qsize 16, out_qsize 7\n",
      "2019-11-08 15:22:32,233 : INFO : EPOCH 2 - PROGRESS: at 95.15% examples, 436424 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:22:33,258 : INFO : EPOCH 2 - PROGRESS: at 96.85% examples, 437174 words/s, in_qsize 17, out_qsize 2\n",
      "2019-11-08 15:22:34,272 : INFO : EPOCH 2 - PROGRESS: at 98.59% examples, 438055 words/s, in_qsize 16, out_qsize 3\n",
      "2019-11-08 15:22:34,936 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-11-08 15:22:34,943 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-11-08 15:22:34,945 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-08 15:22:34,946 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-08 15:22:34,998 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-08 15:22:35,005 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-08 15:22:35,008 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-08 15:22:35,009 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-08 15:22:35,015 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-08 15:22:35,016 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-08 15:22:35,017 : INFO : EPOCH - 2 : training on 41519355 raw words (30350815 effective words) took 69.1s, 439130 effective words/s\n",
      "2019-11-08 15:22:36,080 : INFO : EPOCH 3 - PROGRESS: at 1.38% examples, 419812 words/s, in_qsize 17, out_qsize 2\n",
      "2019-11-08 15:22:37,099 : INFO : EPOCH 3 - PROGRESS: at 3.05% examples, 456761 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:38,111 : INFO : EPOCH 3 - PROGRESS: at 4.71% examples, 470797 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:22:39,111 : INFO : EPOCH 3 - PROGRESS: at 6.32% examples, 478467 words/s, in_qsize 20, out_qsize 2\n",
      "2019-11-08 15:22:40,129 : INFO : EPOCH 3 - PROGRESS: at 7.93% examples, 481818 words/s, in_qsize 19, out_qsize 3\n",
      "2019-11-08 15:22:41,173 : INFO : EPOCH 3 - PROGRESS: at 9.46% examples, 481767 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:22:42,206 : INFO : EPOCH 3 - PROGRESS: at 10.78% examples, 482493 words/s, in_qsize 17, out_qsize 3\n",
      "2019-11-08 15:22:43,216 : INFO : EPOCH 3 - PROGRESS: at 12.07% examples, 484427 words/s, in_qsize 17, out_qsize 2\n",
      "2019-11-08 15:22:44,239 : INFO : EPOCH 3 - PROGRESS: at 13.59% examples, 485315 words/s, in_qsize 16, out_qsize 5\n",
      "2019-11-08 15:22:45,258 : INFO : EPOCH 3 - PROGRESS: at 15.01% examples, 486282 words/s, in_qsize 17, out_qsize 4\n",
      "2019-11-08 15:22:46,259 : INFO : EPOCH 3 - PROGRESS: at 16.46% examples, 487294 words/s, in_qsize 16, out_qsize 3\n",
      "2019-11-08 15:22:47,298 : INFO : EPOCH 3 - PROGRESS: at 17.80% examples, 487172 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:22:48,311 : INFO : EPOCH 3 - PROGRESS: at 19.17% examples, 487737 words/s, in_qsize 18, out_qsize 2\n",
      "2019-11-08 15:22:49,324 : INFO : EPOCH 3 - PROGRESS: at 20.44% examples, 488303 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:22:50,399 : INFO : EPOCH 3 - PROGRESS: at 21.99% examples, 485830 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:51,418 : INFO : EPOCH 3 - PROGRESS: at 23.27% examples, 485951 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:52,510 : INFO : EPOCH 3 - PROGRESS: at 24.57% examples, 484762 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:53,596 : INFO : EPOCH 3 - PROGRESS: at 26.50% examples, 484032 words/s, in_qsize 19, out_qsize 3\n",
      "2019-11-08 15:22:54,659 : INFO : EPOCH 3 - PROGRESS: at 28.36% examples, 483609 words/s, in_qsize 17, out_qsize 3\n",
      "2019-11-08 15:22:55,719 : INFO : EPOCH 3 - PROGRESS: at 30.31% examples, 485944 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:56,738 : INFO : EPOCH 3 - PROGRESS: at 32.22% examples, 486379 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:57,762 : INFO : EPOCH 3 - PROGRESS: at 33.88% examples, 486716 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:58,791 : INFO : EPOCH 3 - PROGRESS: at 35.68% examples, 486966 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:22:59,852 : INFO : EPOCH 3 - PROGRESS: at 37.45% examples, 486766 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:23:00,883 : INFO : EPOCH 3 - PROGRESS: at 39.30% examples, 486841 words/s, in_qsize 19, out_qsize 5\n",
      "2019-11-08 15:23:01,911 : INFO : EPOCH 3 - PROGRESS: at 41.10% examples, 487024 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:23:02,932 : INFO : EPOCH 3 - PROGRESS: at 42.89% examples, 487239 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:23:03,934 : INFO : EPOCH 3 - PROGRESS: at 44.78% examples, 487576 words/s, in_qsize 16, out_qsize 3\n",
      "2019-11-08 15:23:04,951 : INFO : EPOCH 3 - PROGRESS: at 46.54% examples, 487899 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:23:05,971 : INFO : EPOCH 3 - PROGRESS: at 48.26% examples, 488107 words/s, in_qsize 20, out_qsize 1\n",
      "2019-11-08 15:23:06,975 : INFO : EPOCH 3 - PROGRESS: at 50.05% examples, 488531 words/s, in_qsize 18, out_qsize 1\n",
      "2019-11-08 15:23:07,979 : INFO : EPOCH 3 - PROGRESS: at 51.76% examples, 488915 words/s, in_qsize 19, out_qsize 4\n",
      "2019-11-08 15:23:09,029 : INFO : EPOCH 3 - PROGRESS: at 53.34% examples, 488628 words/s, in_qsize 19, out_qsize 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-08 15:23:10,041 : INFO : EPOCH 3 - PROGRESS: at 55.10% examples, 488997 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:23:11,054 : INFO : EPOCH 3 - PROGRESS: at 56.88% examples, 489092 words/s, in_qsize 19, out_qsize 2\n",
      "2019-11-08 15:23:12,089 : INFO : EPOCH 3 - PROGRESS: at 58.60% examples, 489050 words/s, in_qsize 20, out_qsize 0\n",
      "2019-11-08 15:23:13,093 : INFO : EPOCH 3 - PROGRESS: at 60.33% examples, 489298 words/s, in_qsize 18, out_qsize 1\n",
      "2019-11-08 15:23:14,107 : INFO : EPOCH 3 - PROGRESS: at 62.05% examples, 489592 words/s, in_qsize 19, out_qsize 4\n",
      "2019-11-08 15:23:15,134 : INFO : EPOCH 3 - PROGRESS: at 63.96% examples, 489638 words/s, in_qsize 16, out_qsize 3\n",
      "2019-11-08 15:23:16,160 : INFO : EPOCH 3 - PROGRESS: at 65.66% examples, 489657 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:23:17,239 : INFO : EPOCH 3 - PROGRESS: at 67.54% examples, 490365 words/s, in_qsize 19, out_qsize 0\n",
      "2019-11-08 15:23:18,276 : INFO : EPOCH 3 - PROGRESS: at 69.23% examples, 490260 words/s, in_qsize 19, out_qsize 1\n",
      "2019-11-08 15:23:19,302 : INFO : EPOCH 3 - PROGRESS: at 70.41% examples, 487347 words/s, in_qsize 19, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=200, window=3, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)\n",
    "#salvando o treino como model\n",
    "Doc2Vec.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"dirty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-08 12:50:46,995 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.823826789855957),\n",
       " ('unclean', 0.7690278887748718),\n",
       " ('grubby', 0.7626662850379944),\n",
       " ('dusty', 0.7407540678977966),\n",
       " ('grimy', 0.7233736515045166),\n",
       " ('stained', 0.72198486328125),\n",
       " ('smelly', 0.7192343473434448),\n",
       " ('dingy', 0.7174286842346191),\n",
       " ('soiled', 0.6874587535858154),\n",
       " ('grungy', 0.6839725971221924)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('children', 0.703892707824707),\n",
       " ('kid', 0.6817502975463867),\n",
       " ('toddler', 0.6421680450439453),\n",
       " ('baby', 0.6262056231498718),\n",
       " ('kids', 0.6140724420547485),\n",
       " ('teenager', 0.6140565872192383),\n",
       " ('infants', 0.571359395980835),\n",
       " ('toddlers', 0.5665720105171204),\n",
       " ('son', 0.5623359084129333),\n",
       " ('sons', 0.557578444480896)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"child\"]\n",
    "model.wv.most_similar (positive=w1,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.669881284236908),\n",
       " ('spain', 0.6134096384048462),\n",
       " ('hawaii', 0.6114700436592102),\n",
       " ('ottawa', 0.6008871793746948),\n",
       " ('england', 0.6007250547409058),\n",
       " ('barcelona', 0.6006668210029602)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"france\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrified', 0.8359158039093018),\n",
       " ('dismayed', 0.8266574740409851),\n",
       " ('appalled', 0.8173131942749023),\n",
       " ('surprised', 0.803878903388977),\n",
       " ('astonished', 0.801540732383728),\n",
       " ('stunned', 0.7989511489868164)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.6667386889457703),\n",
       " ('blanket', 0.6560165286064148),\n",
       " ('quilt', 0.6504893898963928),\n",
       " ('mattress', 0.6392682194709778),\n",
       " ('sheets', 0.6260127425193787),\n",
       " ('matress', 0.6255035400390625),\n",
       " ('comforter', 0.5884686708450317),\n",
       " ('featherbed', 0.5822139978408813),\n",
       " ('pillows', 0.571463406085968),\n",
       " ('bedsheet', 0.5424074530601501)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71923435"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"dirty\",w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3612816"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Left till here away at to whom past. Feelings laughing at no wondered repeated provided finished. It acceptance thoroughly my advantages everything as. Are projecting inquietude affronting preference saw who. Marry of am do avoid ample as. Old disposal followed she ignorant desirous two has. Called played entire roused though for one too. He into walk roof made tall cold he. Feelings way likewise addition wandered contempt bed indulged. \n",
    "\n",
    "Now seven world think timed while her. Spoil large oh he rooms on since an. Am up unwilling eagerness perceived incommode. Are not windows set luckily musical hundred can. Collecting if sympathize middletons be of of reasonably. Horrible so kindness at thoughts exercise no weddings subjects. The mrs gay removed towards journey chapter females offered not. Led distrusts otherwise who may newspaper but. Last he dull am none he mile hold as. \n",
    "\n",
    "Domestic confined any but son bachelor advanced remember. How proceed offered her offence shy forming. Returned peculiar pleasant but appetite differed she. Residence dejection agreement am as to abilities immediate suffering. Ye am depending propriety sweetness distrusts belonging collected. Smiling mention he in thought equally musical. Wisdom new and valley answer. Contented it so is discourse recommend. Man its upon him call mile. An pasture he himself believe ferrars besides cottage. \n",
    "\n",
    "Demesne far hearted suppose venture excited see had has. Dependent on so extremely delivered by. Yet ï»¿no jokes worse her why. Bed one supposing breakfast day fulfilled off depending questions. Whatever boy her exertion his extended. Ecstatic followed handsome drawings entirely mrs one yet outweigh. Of acceptance insipidity remarkably is invitation. \n",
    "\n",
    "Merry alone do it burst me songs. Sorry equal charm joy her those folly ham. In they no is many both. Recommend new contented intention improving bed performed age. Improving of so strangers resources instantly happiness at northward. Danger nearer length oppose really add now either. But ask regret eat branch fat garden. Become am he except wishes. Past so at door we walk want such sang. Feeling colonel get her garrets own. \n",
    "\n",
    "Performed suspicion in certainty so frankness by attention pretended. Newspaper or in tolerably education enjoyment. Extremity excellent certainty discourse sincerity no he so resembled. Joy house worse arise total boy but. Elderly up chicken do at feeling is. Like seen drew no make fond at on rent. Behaviour extremely her explained situation yet september gentleman are who. Is thought or pointed hearing he.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'feelings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando o model salvo antes\n",
    "model = Doc2Vec.load('model')\n",
    "\n",
    "occur = model.wv.most_similar (positive=word,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emotions', 0.6991713047027588),\n",
       " ('doubts', 0.6158347129821777),\n",
       " ('opinions', 0.5903002619743347),\n",
       " ('metaphors', 0.5541226863861084),\n",
       " ('thoughts', 0.5520182847976685),\n",
       " ('reactions', 0.5494124889373779),\n",
       " ('comments', 0.5415266752243042),\n",
       " ('experiences', 0.5245915651321411),\n",
       " ('reveiws', 0.5243786573410034),\n",
       " ('remarks', 0.5220906734466553),\n",
       " ('feelings', 1)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occur[0][0]\n",
    "occur.append(('feelings',1))\n",
    "\n",
    "occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Left till here away at to whom past. * laughing at no wondered repeated provided finished. It acceptance thoroughly my advantages everything as. Are projecting inquietude affronting preference saw who. Marry of am do avoid ample as. Old disposal followed she ignorant desirous two has. Called played entire roused though for one too. He into walk roof made tall cold he. * way likewise addition wandered contempt bed indulged. \\n\\nNow seven world think timed while her. Spoil large oh he rooms on since an. Am up unwilling eagerness perceived incommode. Are not windows set luckily musical hundred can. Collecting if sympathize middletons be of of reasonably. Horrible so kindness at * exercise no weddings subjects. The mrs * removed towards journey chapter females offered not. Led distrusts otherwise who may newspaper but. Last he dull am none he mile hold as. \\n\\nDomestic confined any but son bachelor advanced remember. How proceed offered her offence shy forming. Returned peculiar pleasant but appetite differed she. Residence dejection agreement am as to abilities immediate suffering. Ye am depending propriety sweetness distrusts belonging collected. Smiling mention he in thought equally musical. Wisdom new and valley answer. Contented it so is discourse recommend. Man its upon him call mile. An pasture he himself believe ferrars besides cottage. \\n\\nDemesne far hearted suppose venture excited see had has. Dependent on so extremely delivered by. Yet \\ufeffno jokes worse her why. Bed one supposing breakfast day fulfilled off depending questions. Whatever boy her exertion his extended. Ecstatic followed handsome drawings entirely mrs one yet outweigh. Of acceptance insipidity remarkably is invitation. \\n\\nMerry alone do it burst me songs. Sorry equal charm joy her those folly ham. In they no is many both. Recommend new contented intention improving bed performed age. Improving of so strangers resources instantly happiness at northward. Danger nearer length oppose really add now either. But ask regret eat branch fat garden. Become am he except wishes. Past so at door we walk want such sang. Feeling colonel get her garrets own. \\n\\nPerformed suspicion in certainty so frankness by attention pretended. Newspaper or in tolerably education enjoyment. Extremity excellent certainty discourse sincerity no he so resembled. Joy house worse arise total boy but. Elderly up chicken do at feeling is. Like seen drew no make fond at on rent. Behaviour extremely her explained situation yet september gentleman are who. Is thought or pointed hearing he.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def relace_word(word, new):\n",
    "    prim_letter = word[0]\n",
    "    return re.sub(r'({}|{})'.format(prim_letter.lower(), prim_letter.upper())+ word[1:],'*',new.strip())\n",
    "\n",
    "\n",
    "for k, v in occur:\n",
    "     text = relace_word(k, text)\n",
    "    \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-08 15:19:01,192 : INFO : loading Doc2Vec object from model\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-5f647dac4f06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \"\"\"\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model saved using code from earlier Gensim Version. Re-loading old model in a compatible way.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \"\"\"\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWordEmbeddingsModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ns_exponent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mns_exponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \"\"\"\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseAny2VecModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m     \"\"\"\n\u001b[0;32m-> 1381\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
